import os
import re
import subprocess
import json
from pathlib import Path
from typing import List, Optional
from urllib.parse import parse_qs, urlparse

import google.generativeai as genai
import markdown
from dotenv import load_dotenv
from flask import Flask, render_template, request

# --- è¨­å®š ---
PORT = int(os.environ.get("PORT", 8081))
MODEL_NAME = "gemini-2.5-flash-lite"
CAPTIONS_DIR = Path("captions")
CAPTIONS_DIR.mkdir(exist_ok=True)

# èµ·å‹•æ™‚ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—: å‰å›æ®‹ã£ãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
print("ğŸ§¹ [èµ·å‹•æ™‚] captionsãƒ•ã‚©ãƒ«ãƒ€ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ä¸­...")
for file in CAPTIONS_DIR.glob("*"):
    try:
        file.unlink()
        print(f"  ğŸ—‘ï¸ å‰Šé™¤: {file.name}")
    except Exception as e:
        print(f"  âš ï¸ å‰Šé™¤å¤±æ•—: {file.name} - {e}")
print("âœ… [èµ·å‹•æ™‚] ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Œäº†\n")

app = Flask(__name__)
app.secret_key = "tsukkomi_secret_key"

load_dotenv()

# Gemini APIã‚­ãƒ¼è¨­å®š
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY_PRIMARY") or os.getenv("GEMINI_API_KEY")

if not GEMINI_API_KEY:
    print("âŒ GEMINI_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
    import sys
    sys.exit(1)

genai.configure(api_key=GEMINI_API_KEY)

def clean_youtube_url(url: str) -> str:
    parsed = urlparse(url)
    if "youtu.be" in parsed.netloc:
        return f"https://www.youtube.com/watch?v={parsed.path.strip('/')}"
    if "youtube.com" in parsed.netloc and "watch" in parsed.path:
        qs = parse_qs(parsed.query)
        video_id = qs.get("v", [None])[0]
        if video_id:
            return f"https://www.youtube.com/watch?v={video_id}"
    return url

def download_captions(youtube_url: str) -> Optional[Path]:
    clean_url = clean_youtube_url(youtube_url)
    cmd = [
        "yt-dlp",
        "--impersonate", "chrome",
        "--extractor-args", "youtube:player_client=web_creator,ios,android",
        "--write-auto-sub",
        "--sub-lang", "ja,en",
        "--skip-download",
        "--output", str(CAPTIONS_DIR / "%(title)s [%(id)s].%(ext)s"),
        clean_url,
    ]

    if os.path.exists("cookies.txt"):
        cmd.insert(1, "--cookies")
        cmd.insert(2, "cookies.txt")

    try:
        subprocess.run(cmd, check=False)
    except Exception as e:
        print(f"âš ï¸ yt-dlp ã‚¨ãƒ©ãƒ¼: {e}")
        return None

    # éš ã—ãƒ•ã‚¡ã‚¤ãƒ« (._*) ã‚’é™¤å¤–
    candidates = [p for p in CAPTIONS_DIR.glob("*.vtt") if not p.name.startswith("._")]
    if not candidates:
        return None

    # å„ªå…ˆé †ä½: ja > en > ä»–
    for p in candidates:
        if ".ja." in p.name: return p
    for p in candidates:
        if ".en." in p.name: return p
    return candidates[0]

def parse_vtt(vtt_path: Path) -> List[str]:
    with vtt_path.open("r", encoding="utf-8") as f:
        lines = f.readlines()

    text_lines: List[str] = []
    skip_next = False
    for line in lines:
        line = line.strip()
        if re.match(r"^\d\d:\d\d:\d\d\.\d\d\d -->", line):
            skip_next = False
            continue
        elif line == "" or line.startswith("WEBVTT") or re.match(r"^\d+$", line):
            continue
        elif not skip_next:
            line = re.sub(r"<.*?>", "", line)
            text_lines.append(line)
            skip_next = True
    return text_lines

def clean_text(text_lines: List[str]) -> str:
    seen, cleaned = set(), []
    for line in text_lines:
        line = line.strip()
        if line and line not in seen:
            seen.add(line)
            cleaned.append(line)
    return "\n".join(cleaned)

def analyze_tsukkomi(text: str, title: str) -> str:
    prompt = f"""
ã‚ãªãŸã¯ãƒ—ãƒ­ã®ãŠç¬‘ã„è©•è«–å®¶ã§ã‚ã‚Šã€è¨€è‘‰éŠã³ã®é”äººã§ã™ã€‚
YouTubeå‹•ç”»ã€Œ{title}ã€ã®æ–‡å­—èµ·ã“ã—ã‹ã‚‰ã€ç‹¬å‰µçš„ãªè¡¨ç¾ã‚„ãƒ„ãƒƒã‚³ãƒŸã‚’æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚

ã€æŠ½å‡ºãƒ»åˆ†æåŸºæº–ã€‘
1. ç‹¬ç‰¹ãªè¨€èªã‚»ãƒ³ã‚¹ï¼ˆé€ èªã€æ¯”å–©ã€ãƒ‘ãƒ¯ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼‰
2. ç‹‚æ°—ã‚’æ„Ÿã˜ã‚‹ã»ã©ã®å¦„æƒ³ãƒˆãƒ¼ã‚¯ã‚„ãƒœã‚±
3. é‹­ã„ãƒ„ãƒƒã‚³ãƒŸã‚„ã€æ–œã‚ä¸Šã®è¦–ç‚¹ã‹ã‚‰ã®æ„Ÿæƒ³

ã€å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã€‘
Markdownå½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
ç‰¹ã«ã€Œãƒ•ãƒ¬ãƒ¼ã‚ºã€ã€Œåˆ†é¡ã€ã€Œãªãœé¢ç™½ã„ã®ã‹ï¼ˆèƒŒæ™¯ãƒ»è¨€è‘‰éŠã³ã®è§£èª¬ï¼‰ã€ã‚’æ˜ç¢ºã«ã—ã¦ãã ã•ã„ã€‚
ãƒ†ãƒ¼ãƒ–ãƒ«å½¢å¼ã‚’æ´»ç”¨ã™ã‚‹ã¨è¦‹ã‚„ã™ã„ã§ã™ã€‚

--- æ–‡å­—èµ·ã“ã—é–‹å§‹ ---
{text}
--- æ–‡å­—èµ·ã“ã—çµ‚äº† ---
"""
    model = genai.GenerativeModel(MODEL_NAME)
    response = model.generate_content(prompt)
    return response.text

@app.route("/", methods=["GET", "POST"])
def index():
    if request.method == "POST":
        url = request.form.get("youtube_url")
        if not url:
            return render_template("tsukkomi_index.html", error="URLã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")

        # æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
        for f in CAPTIONS_DIR.glob("*"):
            try: f.unlink()
            except: pass

        vtt_path = download_captions(url)
        if not vtt_path:
            return render_template("tsukkomi_index.html", error="å­—å¹•ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸï¼ˆå­—å¹•è¨­å®šãŒãªã„ã€ã¾ãŸã¯éå…¬é–‹ãªã©ï¼‰")

        title = vtt_path.stem
        cleaned = clean_text(parse_vtt(vtt_path))
        
        analysis_md = analyze_tsukkomi(cleaned, title)
        analysis_html = markdown.markdown(analysis_md, extensions=["tables", "fenced_code"])
        
        # captionsãƒ•ã‚©ãƒ«ãƒ€ãƒ¼ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        for file in CAPTIONS_DIR.glob("*"):
            try:
                file.unlink()
            except:
                pass
        
        return render_template(
            "tsukkomi_result.html",
            title=title,
            video_url=clean_youtube_url(url),
            analysis_html=analysis_html
        )

    return render_template("tsukkomi_index.html")

if __name__ == "__main__":
    app.run(host="0.0.0.0", port=PORT, debug=False)
